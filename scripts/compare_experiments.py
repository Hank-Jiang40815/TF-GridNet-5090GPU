#!/usr/bin/env python3
"""
å¯¦é©—æ¯”è¼ƒè…³æœ¬
æ¯”è¼ƒå…©å€‹å¯¦é©—çš„è©•ä¼°çµæœ
"""

import csv
import json
from pathlib import Path
import argparse
import numpy as np

def load_experiment(exp_dir):
    """è¼‰å…¥å¯¦é©—è³‡æ–™"""
    exp_dir = Path(exp_dir)
    
    # è¼‰å…¥ CSV
    csv_path = exp_dir / 'evaluation_results.csv'
    results = []
    with open(csv_path, 'r') as f:
        reader = csv.DictReader(f)
        for row in reader:
            results.append({
                'uttid': row['uttid'],
                'si_snr_noisy': float(row['si_snr_noisy']),
                'si_snr_enhanced': float(row['si_snr_enhanced']),
                'improvement': float(row['improvement'])
            })
    
    # è¼‰å…¥ metadata (å¦‚æœå­˜åœ¨)
    metadata_path = exp_dir / 'metadata.json'
    metadata = None
    if metadata_path.exists():
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
    
    return {
        'dir': exp_dir,
        'name': exp_dir.name,
        'results': results,
        'metadata': metadata
    }

def compute_statistics(results):
    """è¨ˆç®—çµ±è¨ˆè³‡è¨Š"""
    improvements = [r['improvement'] for r in results]
    return {
        'count': len(improvements),
        'mean': np.mean(improvements),
        'std': np.std(improvements),
        'min': np.min(improvements),
        'max': np.max(improvements),
        'median': np.median(improvements),
        'q25': np.percentile(improvements, 25),
        'q75': np.percentile(improvements, 75)
    }

def compare_experiments(exp1_dir, exp2_dir):
    """æ¯”è¼ƒå…©å€‹å¯¦é©—"""
    print("=" * 80)
    print("å¯¦é©—æ¯”è¼ƒå ±å‘Š")
    print("=" * 80)
    print()
    
    # è¼‰å…¥å¯¦é©—
    exp1 = load_experiment(exp1_dir)
    exp2 = load_experiment(exp2_dir)
    
    print(f"ğŸ“Š å¯¦é©— 1: {exp1['name']}")
    print(f"ğŸ“Š å¯¦é©— 2: {exp2['name']}")
    print()
    
    # è¨ˆç®—çµ±è¨ˆ
    stats1 = compute_statistics(exp1['results'])
    stats2 = compute_statistics(exp2['results'])
    
    # é¡¯ç¤ºåŸºæœ¬è³‡è¨Š
    print("=" * 80)
    print("åŸºæœ¬è³‡è¨Š")
    print("=" * 80)
    print(f"{'æŒ‡æ¨™':<20} {'å¯¦é©— 1':>15} {'å¯¦é©— 2':>15} {'å·®ç•°':>15}")
    print("-" * 80)
    print(f"{'æ¨£æœ¬æ•¸':<20} {stats1['count']:>15} {stats2['count']:>15} {stats2['count']-stats1['count']:>15}")
    print()
    
    # é¡¯ç¤º SI-SNR æ”¹å–„çµ±è¨ˆ
    print("=" * 80)
    print("SI-SNR æ”¹å–„çµ±è¨ˆ (dB)")
    print("=" * 80)
    print(f"{'æŒ‡æ¨™':<20} {'å¯¦é©— 1':>15} {'å¯¦é©— 2':>15} {'å·®ç•°':>15}")
    print("-" * 80)
    
    for key, label in [
        ('mean', 'å¹³å‡'),
        ('std', 'æ¨™æº–å·®'),
        ('median', 'ä¸­ä½æ•¸'),
        ('min', 'æœ€å°'),
        ('max', 'æœ€å¤§'),
        ('q25', 'ç¬¬25ç™¾åˆ†ä½'),
        ('q75', 'ç¬¬75ç™¾åˆ†ä½')
    ]:
        val1 = stats1[key]
        val2 = stats2[key]
        diff = val2 - val1
        sign = 'â†‘' if diff > 0 else 'â†“' if diff < 0 else '='
        print(f"{label:<20} {val1:>15.2f} {val2:>15.2f} {diff:>14.2f}{sign}")
    
    print()
    
    # æ•ˆèƒ½åˆ†é¡
    print("=" * 80)
    print("æ•ˆèƒ½åˆ†é¡")
    print("=" * 80)
    
    def classify_performance(results):
        excellent = sum(1 for r in results if r['improvement'] > 10)
        good = sum(1 for r in results if 5 < r['improvement'] <= 10)
        moderate = sum(1 for r in results if 0 < r['improvement'] <= 5)
        poor = sum(1 for r in results if r['improvement'] <= 0)
        return excellent, good, moderate, poor
    
    e1_exc, e1_good, e1_mod, e1_poor = classify_performance(exp1['results'])
    e2_exc, e2_good, e2_mod, e2_poor = classify_performance(exp2['results'])
    
    print(f"{'é¡åˆ¥':<20} {'å¯¦é©— 1':>15} {'å¯¦é©— 2':>15} {'å·®ç•°':>15}")
    print("-" * 80)
    print(f"{'å„ªç§€ (>10 dB)':<20} {e1_exc:>15} {e2_exc:>15} {e2_exc-e1_exc:>+15}")
    print(f"{'è‰¯å¥½ (5-10 dB)':<20} {e1_good:>15} {e2_good:>15} {e2_good-e1_good:>+15}")
    print(f"{'ä¸­ç­‰ (0-5 dB)':<20} {e1_mod:>15} {e2_mod:>15} {e2_mod-e1_mod:>+15}")
    print(f"{'å·® (â‰¤0 dB)':<20} {e1_poor:>15} {e2_poor:>15} {e2_poor-e1_poor:>+15}")
    print()
    
    # å¦‚æœæœ‰ metadataï¼Œé¡¯ç¤ºæ¨¡å‹è³‡è¨Š
    if exp1['metadata'] and exp2['metadata']:
        print("=" * 80)
        print("æ¨¡å‹é…ç½®")
        print("=" * 80)
        
        m1 = exp1['metadata'].get('model', {})
        m2 = exp2['metadata'].get('model', {})
        
        print(f"{'åƒæ•¸':<20} {'å¯¦é©— 1':>15} {'å¯¦é©— 2':>15}")
        print("-" * 80)
        
        for key, label in [
            ('n_layers', 'å±¤æ•¸'),
            ('lstm_hidden_units', 'LSTMéš±è—å–®å…ƒ'),
            ('attn_n_head', 'æ³¨æ„åŠ›é ­æ•¸'),
            ('emb_dim', 'åµŒå…¥ç¶­åº¦')
        ]:
            v1 = m1.get(key, 'N/A')
            v2 = m2.get(key, 'N/A')
            print(f"{label:<20} {str(v1):>15} {str(v2):>15}")
        
        print()
        
        # è¨“ç·´è³‡è¨Š
        print("=" * 80)
        print("è¨“ç·´é…ç½®")
        print("=" * 80)
        
        t1 = exp1['metadata'].get('training', {})
        t2 = exp2['metadata'].get('training', {})
        
        print(f"{'åƒæ•¸':<20} {'å¯¦é©— 1':>25} {'å¯¦é©— 2':>25}")
        print("-" * 80)
        
        for key, label in [
            ('total_epochs', 'ç¸½è¨“ç·´è¼ªæ•¸'),
            ('best_epoch', 'æœ€ä½³è¼ªæ•¸'),
            ('gpu', 'GPU'),
            ('pytorch_version', 'PyTorchç‰ˆæœ¬')
        ]:
            v1 = t1.get(key, 'N/A')
            v2 = t2.get(key, 'N/A')
            print(f"{label:<20} {str(v1):>25} {str(v2):>25}")
        
        print()
    
    # é€æ¨£æœ¬æ¯”è¼ƒ
    print("=" * 80)
    print("é€æ¨£æœ¬æ”¹å–„å·®ç•° (å¯¦é©—2 - å¯¦é©—1)")
    print("=" * 80)
    
    # ç¢ºä¿å…©å€‹å¯¦é©—æœ‰ç›¸åŒçš„æ¨£æœ¬
    uttids1 = {r['uttid'] for r in exp1['results']}
    uttids2 = {r['uttid'] for r in exp2['results']}
    common_uttids = uttids1 & uttids2
    
    if len(common_uttids) == 0:
        print("âš ï¸ å…©å€‹å¯¦é©—æ²’æœ‰å…±åŒæ¨£æœ¬")
    else:
        print(f"å…±åŒæ¨£æœ¬æ•¸: {len(common_uttids)}")
        print()
        
        # è¨ˆç®—å·®ç•°
        diffs = []
        for uttid in sorted(common_uttids):
            r1 = next(r for r in exp1['results'] if r['uttid'] == uttid)
            r2 = next(r for r in exp2['results'] if r['uttid'] == uttid)
            diff = r2['improvement'] - r1['improvement']
            diffs.append((uttid, r1['improvement'], r2['improvement'], diff))
        
        # æ’åºæ‰¾å‡ºæœ€å¤§æ”¹å–„å’Œé€€æ­¥
        diffs.sort(key=lambda x: x[3])
        
        print("ğŸ“‰ æœ€å¤§é€€æ­¥ (Top 5):")
        for i, (uttid, imp1, imp2, diff) in enumerate(diffs[:5], 1):
            print(f"  {i}. {uttid}: {imp1:+.2f} dB â†’ {imp2:+.2f} dB ({diff:+.2f} dB)")
        
        print()
        print("ğŸ“ˆ æœ€å¤§æ”¹å–„ (Top 5):")
        for i, (uttid, imp1, imp2, diff) in enumerate(diffs[-5:][::-1], 1):
            print(f"  {i}. {uttid}: {imp1:+.2f} dB â†’ {imp2:+.2f} dB ({diff:+.2f} dB)")
        
        print()
        
        # çµ±è¨ˆå·®ç•°åˆ†å¸ƒ
        diff_values = [d[3] for d in diffs]
        better = sum(1 for d in diff_values if d > 0)
        worse = sum(1 for d in diff_values if d < 0)
        same = sum(1 for d in diff_values if d == 0)
        
        print(f"å¯¦é©— 2 ç›¸å°æ–¼å¯¦é©— 1:")
        print(f"  æ›´å¥½: {better} å€‹æ¨£æœ¬ ({better/len(diff_values)*100:.1f}%)")
        print(f"  æ›´å·®: {worse} å€‹æ¨£æœ¬ ({worse/len(diff_values)*100:.1f}%)")
        print(f"  ç›¸åŒ: {same} å€‹æ¨£æœ¬ ({same/len(diff_values)*100:.1f}%)")
        print(f"  å¹³å‡å·®ç•°: {np.mean(diff_values):+.2f} dB")
    
    print()
    print("=" * 80)
    
    # çµè«–
    print("\nâœ… æ¯”è¼ƒå®Œæˆï¼")
    
    # åˆ¤æ–·å“ªå€‹å¯¦é©—æ›´å¥½
    if stats2['mean'] > stats1['mean']:
        print(f"ğŸ† å¯¦é©— 2 è¡¨ç¾è¼ƒä½³ (å¹³å‡æ”¹å–„ {stats2['mean'] - stats1['mean']:+.2f} dB)")
    elif stats1['mean'] > stats2['mean']:
        print(f"ğŸ† å¯¦é©— 1 è¡¨ç¾è¼ƒä½³ (å¹³å‡æ”¹å–„ {stats1['mean'] - stats2['mean']:+.2f} dB)")
    else:
        print("âš–ï¸ å…©å€‹å¯¦é©—è¡¨ç¾ç›¸ç•¶")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='æ¯”è¼ƒå…©å€‹å¯¦é©—çš„è©•ä¼°çµæœ')
    parser.add_argument('--exp1', type=str, required=True,
                       help='å¯¦é©—1çš„çµæœç›®éŒ„è·¯å¾‘')
    parser.add_argument('--exp2', type=str, required=True,
                       help='å¯¦é©—2çš„çµæœç›®éŒ„è·¯å¾‘')
    
    args = parser.parse_args()
    
    compare_experiments(args.exp1, args.exp2)
