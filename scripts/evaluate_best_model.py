#!/usr/bin/env python3
"""
è©•ä¼°æœ€ä½³è¨“ç·´æ¨¡å‹ - Epoch 100
å¯¦é©—: rtx5090-soundfile-5000ep
æ—¥æœŸ: 2025-11-11
ç‰ˆæœ¬: v2 - å¢åŠ éŸ³è¨Šä¿å­˜åŠŸèƒ½
"""

import sys
import os
import torch
import numpy as np
from pathlib import Path
import soundfile as sf
import librosa
import csv
from datetime import datetime

# æ·»åŠ ä»£ç¢¼è·¯å¾‘
sys.path.insert(0, '/workspace/TFG-Transfer-Package/code')

from memory_optimized_tfgridnet import TFGridNetV2, AudioDataset

def calculate_si_snr(estimate, reference, eps=1e-8):
    """è¨ˆç®— SI-SNR (Scale-Invariant Signal-to-Noise Ratio)"""
    # ç¢ºä¿æ˜¯ä¸€ç¶­å¼µé‡
    if estimate.dim() > 1:
        estimate = estimate.squeeze()
    if reference.dim() > 1:
        reference = reference.squeeze()
    
    # ç§»é™¤å‡å€¼
    estimate = estimate - estimate.mean()
    reference = reference - reference.mean()
    
    # è¨ˆç®—æŠ•å½±
    reference_energy = torch.sum(reference ** 2) + eps
    projection = torch.sum(estimate * reference) * reference / reference_energy
    
    # è¨ˆç®—å™ªéŸ³
    noise = estimate - projection
    
    # è¨ˆç®— SI-SNR
    si_snr = 10 * torch.log10(
        torch.sum(projection ** 2) / (torch.sum(noise ** 2) + eps) + eps
    )
    
    return si_snr.item()

def evaluate_model(checkpoint_path, config_path='/workspace/configs/training_rtx5090.yaml', 
                   save_audio=True, output_dir='/workspace/experiments/inference_results'):
    """è©•ä¼°æ¨¡å‹æ€§èƒ½ä¸¦ä¿å­˜å¢å¼·éŸ³è¨Š"""
    import yaml
    
    print("=" * 80)
    print("ğŸ¯ TF-GridNetV2 æ¨¡å‹è©•ä¼°")
    print("=" * 80)
    print(f"æª¢æŸ¥é»: {checkpoint_path}")
    print(f"é…ç½®æ–‡ä»¶: {config_path}")
    if save_audio:
        print(f"è¼¸å‡ºç›®éŒ„: {output_dir}")
    print()
    
    # è¼‰å…¥é…ç½®
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # è¨­ç½®è¨­å‚™
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è¨­å‚™: {device}")
    
    # å‰µå»ºæ¨¡å‹
    model_config = config['model']['architecture']
    stft_config = config['model']['stft']
    
    model = TFGridNetV2(
        n_srcs=model_config['n_srcs'],
        n_fft=stft_config['n_fft'],
        hop_length=stft_config['hop_length'],
        win_length=stft_config['win_length'],
        n_layers=model_config['n_layers'],
        lstm_hidden_units=model_config['lstm_hidden_units'],
        attn_n_head=model_config['n_heads'],
        emb_dim=model_config['emb_dim'],
        emb_ks=model_config['emb_ks'],
        emb_hs=model_config['emb_hs'],
        activation=model_config['activation'],
        eps=model_config['eps'],
        use_attn=model_config.get('use_multi_head_attention', True),
        use_gradient_checkpointing=False,  # è©•ä¼°æ™‚ä¸éœ€è¦
        use_cross_attn=model_config.get('use_cross_attention', False),
        use_se=model_config.get('use_squeeze_excitation', False),
    ).to(device)
    
    # è¼‰å…¥æª¢æŸ¥é»
    print(f"\nğŸ“¦ è¼‰å…¥æª¢æŸ¥é»...")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # è™•ç† state_dict ä¸­çš„ base_model å‰ç¶´
    state_dict = checkpoint['model_state_dict']
    new_state_dict = {}
    for key, value in state_dict.items():
        if key.startswith('base_model.'):
            new_key = key.replace('base_model.', '')
            new_state_dict[new_key] = value
        else:
            new_state_dict[key] = value
    
    # ä½¿ç”¨ strict=False å› ç‚ºæ¨¡å‹å¯èƒ½æœ‰æœªä½¿ç”¨çš„çµ„ä»¶ï¼ˆå¦‚ cross_attentionï¼‰
    missing_keys, unexpected_keys = model.load_state_dict(new_state_dict, strict=False)
    if missing_keys:
        print(f"   âš ï¸ æœªè¼‰å…¥çš„éµå€¼ ({len(missing_keys)}): é€™äº›æ˜¯æœªä½¿ç”¨çš„çµ„ä»¶")
    if unexpected_keys:
        print(f"   âš ï¸ æ„å¤–çš„éµå€¼ ({len(unexpected_keys)})")
    
    model.eval()
    print(f"âœ… æ¨¡å‹å·²è¼‰å…¥ (Epoch {checkpoint['epoch']})")
    if 'train_loss' in checkpoint and checkpoint['train_loss'] != 'N/A':
        print(f"   è¨“ç·´æå¤±: {checkpoint['train_loss']:.4f}")
    if 'valid_loss' in checkpoint and checkpoint['valid_loss'] != 'N/A':
        print(f"   é©—è­‰æå¤±: {checkpoint['valid_loss']:.4f}")
    if 'loss' in checkpoint:
        print(f"   æå¤±: {checkpoint['loss']:.4f}")
    
    # å‰µå»ºé©—è­‰é›†
    print(f"\nğŸ“Š è¼‰å…¥é©—è­‰é›†...")
    valid_dataset = AudioDataset(
        clean_scp_path='/workspace/TFG-Transfer-Package/data/scp/valid_clean_relative.scp',
        noisy_scp_path='/workspace/TFG-Transfer-Package/data/scp/valid_noisy_relative.scp',
        config=config
    )
    print(f"   é©—è­‰æ¨£æœ¬æ•¸: {len(valid_dataset)}")
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    if save_audio:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        epoch_num = checkpoint['epoch']
        result_dir = Path(output_dir) / f'epoch_{epoch_num}_best_{timestamp}'
        enhanced_dir = result_dir / 'enhanced'
        noisy_dir = result_dir / 'noisy'
        clean_dir = result_dir / 'clean'
        
        for d in [enhanced_dir, noisy_dir, clean_dir]:
            d.mkdir(parents=True, exist_ok=True)
        
        print(f"\nğŸ’¾ éŸ³è¨Šè¼¸å‡ºç›®éŒ„:")
        print(f"   {result_dir}")
        print()
    
    # è©•ä¼°
    print(f"\nğŸ”¬ é–‹å§‹è©•ä¼°...")
    si_snr_improvements = []
    si_snr_noisy_list = []
    si_snr_enhanced_list = []
    audio_results = []  # ä¿å­˜æ¯å€‹æª”æ¡ˆçš„è©³ç´°çµæœ
    
    with torch.no_grad():
        for i in range(len(valid_dataset)):
            try:
                noisy_audio, clean_audio, uttid = valid_dataset[i]
                
                # ç§»å‹•åˆ°è¨­å‚™
                noisy_audio = noisy_audio.unsqueeze(0).to(device)
                clean_audio = clean_audio.to(device)
                
                # æ¨¡å‹æ¨ç†
                enhanced_audio = model(noisy_audio)
                enhanced_audio = enhanced_audio.squeeze(0).squeeze(0)
                
                # ç¢ºä¿é•·åº¦ä¸€è‡´
                min_len = min(enhanced_audio.shape[0], clean_audio.shape[0])
                enhanced_audio = enhanced_audio[:min_len]
                clean_audio = clean_audio[:min_len]
                noisy_for_calc = noisy_audio.squeeze(0).squeeze(0)[:min_len]
                
                # è¨ˆç®— SI-SNR
                si_snr_noisy = calculate_si_snr(noisy_for_calc, clean_audio)
                si_snr_enhanced = calculate_si_snr(enhanced_audio, clean_audio)
                improvement = si_snr_enhanced - si_snr_noisy
                
                si_snr_noisy_list.append(si_snr_noisy)
                si_snr_enhanced_list.append(si_snr_enhanced)
                si_snr_improvements.append(improvement)
                
                # ä¿å­˜éŸ³è¨Šæª”æ¡ˆ
                if save_audio:
                    # ä¿å­˜å¢å¼·å¾Œçš„éŸ³è¨Š
                    enhanced_path = enhanced_dir / f"{uttid}.wav"
                    sf.write(enhanced_path, enhanced_audio.cpu().numpy(), config['data']['preprocessing']['target_sample_rate'])
                    
                    # ä¿å­˜å™ªéŸ³éŸ³è¨Šï¼ˆåƒè€ƒï¼‰
                    noisy_path = noisy_dir / f"{uttid}.wav"
                    sf.write(noisy_path, noisy_for_calc.cpu().numpy(), config['data']['preprocessing']['target_sample_rate'])
                    
                    # ä¿å­˜ä¹¾æ·¨éŸ³è¨Šï¼ˆground truthï¼‰
                    clean_path = clean_dir / f"{uttid}.wav"
                    sf.write(clean_path, clean_audio.cpu().numpy(), config['data']['preprocessing']['target_sample_rate'])
                
                # è¨˜éŒ„çµæœ
                audio_results.append({
                    'uttid': uttid,
                    'si_snr_noisy': si_snr_noisy,
                    'si_snr_enhanced': si_snr_enhanced,
                    'improvement': improvement
                })
                
                if (i + 1) % 50 == 0:
                    print(f"   è™•ç†é€²åº¦: {i+1}/{len(valid_dataset)} "
                          f"(å¹³å‡æ”¹å–„: {np.mean(si_snr_improvements):.2f} dB)")
                
            except Exception as e:
                print(f"   âš ï¸  æ¨£æœ¬ {i} ({uttid if 'uttid' in locals() else 'unknown'}) è©•ä¼°å¤±æ•—: {e}")
                continue
    
    # è¨ˆç®—çµ±è¨ˆ
    print("\n" + "=" * 80)
    print("ğŸ“Š è©•ä¼°çµæœ")
    print("=" * 80)
    print(f"æˆåŠŸè©•ä¼°æ¨£æœ¬æ•¸: {len(si_snr_improvements)}/{len(valid_dataset)}")
    print()
    print("SI-SNR çµ±è¨ˆ:")
    print(f"  å™ªéŸ³éŸ³è¨Šå¹³å‡ SI-SNR:    {np.mean(si_snr_noisy_list):>8.2f} dB")
    print(f"  å¢å¼·éŸ³è¨Šå¹³å‡ SI-SNR:    {np.mean(si_snr_enhanced_list):>8.2f} dB")
    print(f"  å¹³å‡æ”¹å–„:               {np.mean(si_snr_improvements):>8.2f} dB")
    print(f"  æ¨™æº–å·®:                 {np.std(si_snr_improvements):>8.2f} dB")
    print(f"  æœ€ä½³æ”¹å–„:               {np.max(si_snr_improvements):>8.2f} dB")
    print(f"  æœ€å·®æ”¹å–„:               {np.min(si_snr_improvements):>8.2f} dB")
    print("=" * 80)
    
    # ä¿å­˜çµæœåˆ° CSV
    if save_audio and len(audio_results) > 0:
        csv_path = result_dir / 'evaluation_results.csv'
        with open(csv_path, 'w', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=['uttid', 'si_snr_noisy', 'si_snr_enhanced', 'improvement'])
            writer.writeheader()
            writer.writerows(audio_results)
        
        print(f"\nğŸ’¾ çµæœå·²ä¿å­˜:")
        print(f"   CSV å ±å‘Š: {csv_path}")
        print(f"   å¢å¼·éŸ³è¨Š: {enhanced_dir} ({len(list(enhanced_dir.glob('*.wav')))} å€‹æª”æ¡ˆ)")
        
        # æ¨™è¨»é—œéµæ¨£æœ¬
        if len(audio_results) > 0:
            sorted_results = sorted(audio_results, key=lambda x: x['improvement'])
            best_samples = sorted_results[-5:]  # æœ€ä½³5å€‹
            worst_samples = sorted_results[:5]  # æœ€å·®5å€‹
            
            highlights_path = result_dir / 'highlights.txt'
            with open(highlights_path, 'w') as f:
                f.write("=" * 80 + "\n")
                f.write("é—œéµæ¨£æœ¬æ¨™è¨»\n")
                f.write("=" * 80 + "\n\n")
                
                f.write("ğŸ† æœ€ä½³æ”¹å–„ Top 5:\n")
                for r in reversed(best_samples):
                    f.write(f"  {r['uttid']}: {r['improvement']:+.2f} dB "
                           f"({r['si_snr_noisy']:.2f} â†’ {r['si_snr_enhanced']:.2f})\n")
                
                f.write("\nâš ï¸ æœ€å·®æ”¹å–„ Top 5:\n")
                for r in worst_samples:
                    f.write(f"  {r['uttid']}: {r['improvement']:+.2f} dB "
                           f"({r['si_snr_noisy']:.2f} â†’ {r['si_snr_enhanced']:.2f})\n")
            
            print(f"   é—œéµæ¨£æœ¬: {highlights_path}")
    
    # ä¿å­˜çµæœå­—å…¸
    results = {
        'checkpoint': checkpoint_path,
        'epoch': checkpoint['epoch'],
        'num_samples': len(si_snr_improvements),
        'si_snr_noisy_mean': float(np.mean(si_snr_noisy_list)),
        'si_snr_enhanced_mean': float(np.mean(si_snr_enhanced_list)),
        'si_snr_improvement_mean': float(np.mean(si_snr_improvements)),
        'si_snr_improvement_std': float(np.std(si_snr_improvements)),
        'si_snr_improvement_max': float(np.max(si_snr_improvements)),
        'si_snr_improvement_min': float(np.min(si_snr_improvements)),
    }
    
    if save_audio:
        results['output_dir'] = str(result_dir)
    
    return results, si_snr_improvements

if __name__ == '__main__':
    checkpoint_path = '/workspace/experiments/tfgridnetv2_rtx5090_baseline/checkpoint_epoch_100_best.pth'
    
    if not os.path.exists(checkpoint_path):
        print(f"âŒ æ‰¾ä¸åˆ°æª¢æŸ¥é»: {checkpoint_path}")
        sys.exit(1)
    
    results, improvements = evaluate_model(checkpoint_path)
    
    print("\nâœ… è©•ä¼°å®Œæˆï¼")
